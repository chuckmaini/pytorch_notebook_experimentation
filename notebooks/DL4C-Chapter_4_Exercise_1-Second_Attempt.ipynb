{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4, Exercise 1: Implement your own Learner\n",
    "\n",
    "> Create your own implmentation of Learner from scratch, based on the training loop shown in this chapter.\n",
    "\n",
    "As a reminder, the loop is:\n",
    "\n",
    "- Init\n",
    "- Predict\n",
    "- Loss \n",
    "- Gradient\n",
    "- Step\n",
    "- Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the boilerplate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc2d6eb8c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42) # Life, the Universe, and Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the signature from the book; however, for now I'm going to leave out metrics.  I may come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model.  [Weights are  initialized for us](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = nn.Sequential(\n",
    "    nn.Linear(in_features=28*28, out_features=30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data loader...which I guess means we'll need some data.  We'll use the FastAI 3/7 image set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/aardvark/.fastai/data/mnist_sample/labels.csv'),Path('/home/aardvark/.fastai/data/mnist_sample/valid'),Path('/home/aardvark/.fastai/data/mnist_sample/train')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load those into tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_3 = torch.stack([tensor(Image.open(o)) for o in (path /'train/3').ls().sorted()]).float() / 255.0\n",
    "training_7 = torch.stack([tensor(Image.open(o)) for o in (path /'train/7').ls().sorted()]).float() / 255.0\n",
    "len(training_3), len(training_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([training_3, training_7]).view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1] * len(training_3) + [0] * len(training_7))\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2038, 784]), torch.Size([2038]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3 = torch.stack([tensor(Image.open(o)) for o in (path / 'valid/3').ls().sorted()]).float() / 255.0\n",
    "valid_7 = torch.stack([tensor(Image.open(o)) for o in (path / 'valid/7').ls().sorted()]).float() / 255.0\n",
    "valid_x = torch.cat([valid_3, valid_7]).view(-1, 28*28)\n",
    "valid_y = tensor([1] * len(valid_3) + [0] * len(valid_7))\n",
    "valid_dset = list(zip(valid_x, valid_y))\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up would be optimizer.  I'm going to use the PyTorch SGD optimizer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimizer = optim.SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to try some training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLearner():\n",
    "    \n",
    "    def __init__(self, dl, model, opt):\n",
    "        self.dl_train = dl[0]\n",
    "        self.dl_valid = dl[1]\n",
    "        self.model = model\n",
    "        self.opt = opt(self.model.parameters(), lr=0.1)\n",
    "        \n",
    "    def mnist_loss(self, preds, targets):\n",
    "        preds = preds.sigmoid()\n",
    "        return torch.where(targets==1, 1-preds, preds).mean()\n",
    "    \n",
    "    def batch_accuracy(self, xb, yb):\n",
    "        preds = xb.sigmoid()\n",
    "        correct = (preds > 0.5) == yb\n",
    "        return correct.float().mean()\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        accs = [self.batch_accuracy(self.model(x), y) for x, y in self.dl_valid]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "    \n",
    "    def cal_grad(self, x, y):\n",
    "        preds = self.model(x)\n",
    "        loss = self.mnist_loss(preds, y)\n",
    "        loss.backward\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        for x, y in self.dl_train:\n",
    "            self.cal_grad(x, y)\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "    def fit(self, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch(), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_learner = MyLearner([dl, valid_dl], my_model, my_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 0.4932 "
     ]
    }
   ],
   "source": [
    "my_learner.fit(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status\n",
    "\n",
    "This approach came from [here](https://forums.fast.ai/t/chapter-4-further-research-building-a-learner-from-scratch/78474), and seems to be the only discussion of this exercise on the forum.  The implementation is a great deal simpler than mine, so I thought it was worth trying.\n",
    "\n",
    "The poster was asking about one problem they encountered:\n",
    "\n",
    "> I have used the SGD directly as my optimizer, when I fit the learner without the “self.opt.zero_grad” step in the “train_epoch” method it works fine(getting me a score above 0.96 - 0.97- which it should actually do) but when I run it with the “self.opt.zero_grad” step it kind of sticks at one point getting a value eg:0.4957 for “n” number of epochs.\n",
    "\n",
    "That is:\n",
    "\n",
    "- using SGD directly, with the `opt.zero_grad()` line in `train_epoch` commented out, accuracy is ~ 0.91 as expected;\n",
    "- when uncommenting `opt.zero_grad()`, accuracy gets stuck\n",
    "\n",
    "However, I'm noticing that no matter what I set those to.  Not sure what's going wrong.\n",
    "\n",
    "I did note what looks like double sigmoid: it's in the last layer of the model and in the class methods.  Some brief experimentation with that did not appear to change things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
