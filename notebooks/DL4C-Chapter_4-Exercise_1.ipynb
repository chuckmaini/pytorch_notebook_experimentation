{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4, Exercise 1: Implement your own Learner\n",
    "\n",
    "> Create your own implmentation of Learner from scratch, based on the training loop shown in this chapter.\n",
    "\n",
    "As a reminder, the loop is:\n",
    "\n",
    "- Init\n",
    "- Predict\n",
    "- Loss \n",
    "- Gradient\n",
    "- Step\n",
    "- Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the boilerplate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f459c77fc90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(42) # Life, the Universe, and Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the signature from the book; however, for now I'm going to leave out metrics.  I may come back to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLearner():\n",
    "    \n",
    "    def __init__(self, loader, model, opt_func, loss_func, metrics=None):\n",
    "        self.loader = loader\n",
    "        self.model = model\n",
    "        self.opt_func = opt_func\n",
    "        self.loss_func = loss_func\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def fit(self, iterations=10):\n",
    "        '''Fit method \n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know that I'll do every convenience function they have -- `learn.recorder.values()` for example -- but I'll see what I can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our model.  [Weights are  initialized for us](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(in_features=28*28, out_features=30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data loader...which I guess means we'll need some data.  We'll use the FastAI 3/7 image set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/aardvark/.fastai/data/mnist_sample/labels.csv'),Path('/home/aardvark/.fastai/data/mnist_sample/valid'),Path('/home/aardvark/.fastai/data/mnist_sample/train')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load those into tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_3 = torch.stack([tensor(Image.open(o)) for o in (path /'train/3').ls().sorted()]).float() / 255.0\n",
    "training_7 = torch.stack([tensor(Image.open(o)) for o in (path /'train/7').ls().sorted()]).float() / 255.0\n",
    "len(training_3), len(training_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training_data = torch.cat([training_3, training_7])\n",
    "all_training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to remember how to change the shape to match our model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([12396, 784]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_3[0].view(-1).shape, all_training_data.view(-1, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_3 = torch.ones([len(training_3)])\n",
    "labels_7 = torch.zeros([len(training_7)])\n",
    "all_training_labels = torch.cat([labels_3, labels_7])\n",
    "all_training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6131"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoMoreData(Exception):\n",
    "    '''Nothing left, yo\n",
    "    '''\n",
    "\n",
    "class MyLoader():\n",
    "    def __init__(self, training_data, labels, batch_size=5): # batch size picked randomly\n",
    "        assert len(training_data) == len(labels)\n",
    "        self.length = len(training_data)\n",
    "        self.training_data = training_data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.counter = 0\n",
    "        \n",
    "    def next(self):\n",
    "        '''Yield next batch of data.\n",
    "        '''\n",
    "        if self.counter == -1:\n",
    "            # Using this as a signal we're at the end of our rope\n",
    "            raise NoMoreData\n",
    "        if (self.length - self.counter > self.batch_size):\n",
    "            start = self.counter\n",
    "            end = self.counter + self.batch_size\n",
    "            self.counter += self.batch_size\n",
    "            training_data_to_return =  self.training_data[start:end]\n",
    "            training_labels_to_return = self.labels[start:end]\n",
    "        elif (self.length - self.counter < self.batch_size):\n",
    "            start = self.counter\n",
    "            self.counter = -1\n",
    "            training_data_to_return = self.training_data[start:]\n",
    "            training_labels_to_return = self.labels[start:]\n",
    "        return (training_data_to_return, training_labels_to_return)\n",
    "    \n",
    "    def reset(self):\n",
    "        '''Reset counter so we can get more data\n",
    "        '''\n",
    "        self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be interesting to try and make this more like C library calls (not sure what the usual practice is there, but I'll bet you I'm not following it ðŸ¤£).  It would also be interesting to make this a Python yielder (oh, there's a better term for that...).  But for now, I'll stick with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_loader = MyLoader(training_data=all_training_data.view(-1, 28*28), labels=all_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([5]), 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = my_training_loader.next()\n",
    "a.shape, b.shape, my_training_loader.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_training_loader.reset()\n",
    "my_training_loader.counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aw crap...so:  next up would be optimizer.  I want to use the PyTorch SGD optimizer...but this is pretty closely tied with the rest of the Pytorch model API:\n",
    "\n",
    "> To construct an Optimizer you have to give it an iterable containing the parameters (all should be Variable s) to optimize. Then, you can specify optimizer-specific options such as the learning rate, weight decay, etc.\n",
    "\n",
    "```\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam([var1, var2], lr=0.0001)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but wait: we *have* got a PyTorch model :doh:.  Let's use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_optimizer = optim.SGD(simple_net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for loss function, let's just go simple and use mse.   We'll save something fancier for when we get into MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(predicted, actual):\n",
    "    return (F.mean(predicted - actual))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to try some training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loader = MyLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Run the loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
